<!doctype html><html lang=ru-ru><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Алексей Жидков"><meta name=description content="https://azhidkov.pro/"><meta property="og:site_name" content="Алексей Жидков"><meta property="og:title" content="Как я превратил легаси-проект в конфетку за полгода. Том 2 - Алексей Жидков"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://azhidkov.pro/drafts/project-e-retro/project-e-part2/"><meta property="og:image" content="https://azhidkov.pro/"><meta name=twitter:card content="summary"><meta name=twitter:site content="https://azhidkov.pro/drafts/project-e-retro/project-e-part2/"><meta name=twitter:image content="https://azhidkov.pro/"><base href=https://azhidkov.pro/drafts/project-e-retro/project-e-part2/><title>Как я превратил легаси-проект в конфетку за полгода. Том 2 - Алексей Жидков</title><link rel=canonical href=https://azhidkov.pro/drafts/project-e-retro/project-e-part2/><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700"><link rel=stylesheet href=/css/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.2.0/css/all.css><link rel=stylesheet href=https://azhidkov.pro/css/custom.css><link rel=stylesheet href=https://azhidkov.pro/css/github.css><link rel=stylesheet href=https://azhidkov.pro/css/JetBrains-Mono.css><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=alternate href=https://azhidkov.pro/index.xml type=application/rss+xml title="Алексей Жидков"><link href=https://azhidkov.pro/index.xml rel=feed type=application/rss+xml title="Алексей Жидков"><meta name=generator content="Hugo 0.80.0"></head><body><main class=wrapper><link rel=apple-touch-icon sizes=180x180 href=apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://azhidkov.pro/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://azhidkov.pro/favicon-16x16.png><link rel=manifest href=site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><link href="https://fonts.googleapis.com/css?family=Roboto" rel=stylesheet type=text/css><nav class=navigation><section class=container style=height:100%><img src=https://azhidkov.pro/images/logo.svg class=logo>
<a class=navigation-title href=/>Алексей Жидков</a>
<input type=checkbox id=menu-control>
<label class="menu-mobile float-right" for=menu-control><span class="btn-mobile float-right">&#9776;</span><ul class=navigation-list><li class="navigation-item align-left"><a class=navigation-link href=https://azhidkov.pro/ergo-approach/landing>Эргономичный подход</a></li><li class="navigation-item align-left"><a class=navigation-link href=https://azhidkov.pro/effects-diagram/landing>Диаграмма Эффектов</a></li><li class="navigation-item align-left"><a class=navigation-link href=https://azhidkov.pro/posts>Блог</a></li><li class="navigation-item align-left"><a class=navigation-link href=https://azhidkov.pro/portfolio>Портфолио</a></li><li class="navigation-item align-left"><a class=navigation-link href=https://azhidkov.pro/>Контакты</a></li><li class=mobile-menu-lang-separator-full><hr></li></ul></label></section></nav><div class=content><section class="container page"><article><header><h1>Как я превратил легаси-проект в конфетку за полгода. Том 2</h1></header><section class="doc-section level-1"><h2 id=_введение><a class=link href=#_введение>Введение</a></h2><p>Это второй том эпопеи, о том как я превратил легаси-систему в конфетку за полгода:</p><div class="olist arabic"><ol class=arabic><li><a href=https://azhidkov.pro/posts/23/09/project-e-part1/>Том первый. "Пациент скорее мёртв, чем жив"</a> - описание проекта, история получения разрешения на реинжиниринг и планирование работ</li><li>Том второй. "Доктор сказал в морг, значит в морг" - описание процесса работы, что пошло не по плану, как факапились в проде и чем всё закончилось</li><li>Том третий. "Анатомический атлас конфетки" - детали реализации "конфетки"</li><li>Том четвёртый. "Это наследственное" - какие проблемы были вызваны сменой архитектуры и стэка, а так же необходимостью параллельной работы со старым бэком</li></ol></div><p>Первая часть закончилась на том, что я составил план, которого мне оставалось придерживаться.
В этой части я расскажу о том, насколько мне это удалось.</p></section><section class="doc-section level-1"><h2 id=_процесс_работы_команды><a class=link href=#_процесс_работы_команды>Процесс работы команды</a></h2><p>Глобально процесс работы мы организовали "по классике" - псевдоскрам с двухнедельными спринтами и дейликами.</p><p>Перед стартом каждого спринта я для каждого эндпоинта, запланированного на этот спринт, назначал ответственного за него разработчика.
Процесс работы внутри спринта у нас менялся несколько раз и в конечном итоге мы остановились на таком:</p><div class="olist arabic"><ol class=arabic><li>Разработчик создаёт фича-ветку от мастера для каждого эндпоинта;</li><li>Разработчик реализует эндпоинт и проходит ревью в ветке;</li><li>Фича-ветка мёржится в мастер;</li><li>Раз в спринт (седьмой день из десяти) объявляется код фриз;</li><li>QA начинает тестировать релиз-кандидат на dev-стенде, мёржи новых эндпоинтов в мастер запрещены;</li><li>На десятый день (или после того, как QA проверят все задачи, вошедшие в версию), на мастер вешается тег и он заливается на stage-стенд, там гоняются автоматические тесты QA-команды;</li><li>Утром одиннадцатого дня спринта (или на следующий рабочий день, после заливки на стейдж) тег заливается на prod-стенд;</li><li>Код фриз снимается, запускается очередной спринт/релизный цикл.</li></ol></div><p>Единственным, что было у нас не как у всех <em>[из тех команд, в котрых я работал]</em> - на дейликах мы рассказывали не кто чем занимался и будет заниматься, а выясняли кто что должен сделать для того, чтобы каждая задача в работе максимально быстро оказалась на проде.
Сложно сказать, помог ли нам такой формат быстрее закончить реинжиниринг, но лично мне ближе фокус на достижении целей, а не максимизации утилизации ресурсов.</p><aside class=sidebar><h6 class=block-title>Что я вынес для себя</h6><div class="olist arabic"><ol class=arabic><li>Спринты прекрасно работают для реинжиниринга, так как в нём нет извечной проблемы, когда посреди спринта от заказчика прилетает горячий пирожок, который надо было сделать вчера;</li><li>Дейлики структурированные задачам мне подходят больше, чем дейлики структурированные по людям.</li></ol></div></aside></section><section class="doc-section level-1"><h2 id=_отслеживание_прогресса><a class=link href=#_отслеживание_прогресса>Отслеживание прогресса</a></h2><p>В конце каждого спринта я подбивал факт (какие эндпоинты были сделаны за спринт) и актуализировал план (перераспределял оставшиеся эндпоинты по оставшимся спринтам).
Источниками изменений в плане были не только не выполнение плана, но и перевыполнение плана, и удаление эндпоинтов из плана (в основном это были RPC-эндпионты, которые теряли смысл после объединения баз данных аккаунтов с наблюдением и профиля с дневником), и помещение эндпоинтов в один спринт (после обнаружения в процессе работы их высокой сцепленности).</p><p>План и факт я вёл в таких табличках в Confluence:</p><div class=image-block><img src=/drafts/project-e-retro/images/project-e-part2-ade17.png alt="project e part2 ade17"></div><p>Первые спринтов 6 я действовал по принципу всё или ничего - фича и трудозатраты не неё переносится в факт только полностью и после того как она пройдёт QA и окажется stage-стенде.</p><p>Мотивацией такого подхода было то, что я боялся, что мы свалимся в имитацию бурной деятельности без видимых результатов для заказчика.</p><p>Однако из-за такого подхода у нас пару спринтов получилось 0 единиц сделанной работы и в целом видимая мощность команды сильно прыгала (как видно на скрине), из-за чего сложно было понять попадаем ли мы в план.
Поэтому после 6 спринта я перешёл на пропорциональный перенос работ в факт - на глаз определял процент выполнения задачи и соответствующий процент "майки" заносил в факт, уменьшая остаток в плане.</p><aside class=sidebar><h6 class=block-title>Что я вынес для себя</h6><div class="olist arabic"><ol class=arabic><li>Отслеживать прогресс надо процентами выполнения задач, а не штуками;</li></ol></div></aside></section><section class="doc-section level-1"><h2 id=_как_проходил_деплой><a class=link href=#_как_проходил_деплой>Как проходил деплой</a></h2><p>С деплоем мы тоже ничего нового не выдумали и воспользовались стратегией <a href=https://martinfowler.com/bliki/StranglerFigApplication.html>Strangler Fig</a>.</p><p>Завели новый сервис в k8s-кластере и начали в нём реализовывать эндопинты.
По мере реализации эндпоинтов на уровне Ingress переводили запросы на новый бэк.</p><p>В целом эта стратегия хорошо сработала и ни разу не принесла нам существенных проблем.
Возможно, в том числе и потому, что я старался минимизировать риски при определении порядка реинжиниринга эндпоинтов (подробно описано в <a href=https://azhidkov.pro/posts/23/09/project-e-part1/#_планирование_реинжиниринга>в первом томе</a>).</p><p>Но пара небольших сложностей всё-таки возникла.</p><p>Один раз мы сломали dev-стенд из-за того, что перевели на новый бэк эндпоинт, путь которого был префиксом к ещё не реализованному эндпоинту.
В результате мы примерно час потратили на чатики и выяснение кто виноват, а на корректную настройку роутинга у девопса ушло чуть больше обычных пяти минут.</p><p>Так же мы несколько раз задерживали релиз готовых эндпоинтов (перевод трафика на них), так как на том же пути но с другими методами оставались ещё нереализованные эндпоинты.
Тут девопс сказал, что в принципе это можно сделать, но надо изучать вопрос и мы решили, что релиз этих эндпоинтов может немного подождать.</p><aside class=sidebar><h6 class=block-title>Что я вынес для себя</h6><div class="olist arabic"><ol class=arabic><li>Strangler Fig работает, в следующий раз надо делать так же.</li></ol></div></aside></section><section class="doc-section level-1"><h2 id=_что_пошло_не_по_плану><a class=link href=#_что_пошло_не_по_плану>Что пошло не по плану</a></h2><section class="doc-section level-2"><h3 id=_спринты><a class=link href=#_спринты>Спринты</a></h3><p>Первое что пошло не по плану - скорость работы команды в первые два спринта.
При оценке задач я ориентировался на среднюю скорость работы и не учёл несколько факторов, осложнявших старт:</p><div class="olist arabic"><ol class=arabic><li>В новом проекте приходилось сетапать много "инфраструктурного" кода (например, запуск тестконтейнеров без поломки кэша Spring-контекстов), и решать нетиповые задачи, вызванные сменой архитектуры (например, настраивать работу с несколькими DataSource в Spring Data JDBC);</li><li>Команда видела C# в первый раз в жизни, и для юниоров читать код (который фактически выступал в роли ТЗ) на незнакомом языке было довольно сложно;</li><li>Команда не ориентировалась в кодовой базе оригинального проекта, так как не работала с ним до начала реинжиниринга;</li><li>Приходилось искать решения нетипичных проблем из-за наследия .net-бэка (например, обработку CamelCase enum-ов в (де)сериализации DTO).</li></ol></div><p>Из-за этого (плюс стратегия "всё или ничего" в учёте факта) за первые два спринта (или за 25% изначально запланированных спринтов) мы смогли сделать только 5% работы.
Поэтому после второго спринта пришлось сказать, что это была "разминка" и вот теперь оставшиеся 95% работы мы точно сделаем за 8 спринтов.
Благо у нас был запас по времени в 17 человеко/дней, так как при планировании спринтов, я настолько оптимистично набирал в них задачи, что затолкал работ на 177 дней в спринты на 160 дней (8 спринтов * 2 человека * 10 дней в спринте).</p><p>После этой коррекции в целом всё пошло более-менее по плану и в конечном итоге мы уложились в 10 спринтов, единственное что в последнем спринте одному разработчику пришлось устроить 24 часовой хакатон (по собственной инициативе).</p><p>Вся эта драмма хорошо видна на графике процента выполнения проекта:</p><div class=image-block><img src=/drafts/project-e-retro/images/project-e-part2-1e7be.png alt="project e part2 1e7be"></div></section><section class="doc-section level-2"><h3 id=_тестирование_силами_разработчиками><a class=link href=#_тестирование_силами_разработчиками>Тестирование силами разработчиками</a></h3><section class="doc-section level-3"><h4 id=_как_это_должно_было_быть><a class=link href=#_как_это_должно_было_быть>Как это должно было быть</a></h4><p>Вообще Эргономичный подход предполагает вполне конкретный план тестирования.
Его полное описание пока не опубликовано, но суть его сводится к следующими принципами:</p><div class="olist arabic"><ol class=arabic><li>Тестируется система в конфигурации максимально приближенной к боевой.
В частности мокаются только внешние и дорогие или нестабильные зависимости (например, внешний сервис отправки почты), и мокаются они на уровне HTTP.</li><li>Тесты взаимодействуют с системой через публичное API - в общем случае и сетап и действие и верификация выполняются через него.
Работа через "кишочки" допустима, но каждый такой случай рассматривается отдельно и взвешивается ценность теста, его сцепленность с продовым кодом и потенциальные последствия этой сцепленности;</li><li>Тесты пишутся исходя из сценариев использования - каждый юзкейс в ТЗ, должен быть покрыть тестом;</li><li>Все задокументированные ошибки API должны быть покрыты тестами (тут, при необходимости, допускается использование моков);</li><li>В бизнес-логике тестами должны быть покрыты все ветки.
Если бизнес-логика развесистая, её допустимо тестировать в обход публичного API и напрямую вызывать функции ядра.
Чтобы упростить тестирование бизнес-логики, она должна быть реализованна в чистых функциях без ввода-вывода.</li></ol></div><p>И в моей практике эти принципы работают очень хорошо - по статистике, в проектах, покрытых такими тестами, команда QA находит мажорные баги примерно раз в три месяца.
Под мажорными я понимаю баги, которые могли бы затронуть большинство пользователей.</p><p>Но в Проекте Э пришлось отойти от этих принципов.
И пожалеть об этом.</p></section><section class="doc-section level-3"><h4 id=_как_это_было><a class=link href=#_как_это_было>Как это было</a></h4><p>Честно говоря, я уже не помню конкретных причин (дело было почти год назад), но я не стал в тестах поднимать контейнеры старого бэка.
Скорее всего я решил так сделать из-за того что <em>[быстро]</em> не придумал как "натравить" старый бэк на БД в testconainers-ах.</p><p>И из-за того, что мы шли снаружи внутрь и начинали с методов чтения, у нас не было ручек для сетапа фикстуры тестов и верификации через публичное API.
И в целом писать тесты на сценарии использование мы не могли, потому что они нам не достались от старой команды, а времени и денег на реинжиниринг ещё и их не было.
Поэтому тестировать я планировал не сценарии использования, а отдельные эндпоинты.</p><p>Соответственно, новый план тестирования был такой:</p><div class="olist arabic"><ol class=arabic><li>Сначала пишем тест на отдельный эндпоинт, который проходит на старом бэке, поднятом разработчиком руками;</li><li>Переводим тест на вызов нового бэка;</li><li>Выполняем реинжиниринг этого эндпоинта;</li></ol></div><p>Но практически сразу в этом плане обнаружилась дыра - как сетапить фикстуру?
Через публичное API нельзя, так как его не будет на новом бэке.
А через БД нельзя, так как было не понятно как натравить старый бэк на базу в testcontainers.</p><p>В итоге мы начали писать тесты сразу на эндпоинты в новом бэке и сетапить фикстуру SQL-скриптами.
А RPC-вызовы к старому бэку мокали на уровне RabbitMQ.</p><p>Кроме того, из соображений минимизации сроков реинжиниринга, мы отказались от покрытия тестами негативных сценариев.</p><p>За все эти решения мы поплатились большим (84 штуки за 5.5 месяцев) количеством багов и хрупкостью тестов.</p></section><section class="doc-section level-3"><h4 id=_к_чему_это_привело><a class=link href=#_к_чему_это_привело>К чему это привело</a></h4><section class="doc-section level-4"><h5 id=_баги><a class=link href=#_баги>Баги</a></h5><p>Большинство багов было связано с нарушением обратной совместимости.
Но были и баги в негативных сценариях, и баги вида "тесты на метод А проходят, тесты на метод Б проходят, а вот когда фронт зовёт метод А, а потом метод Б - всё взрывается".</p><p>Баги обратной совместимости мы в конечном итоге победили такой схемой:</p><div class="olist arabic"><ol class=arabic><li>Перед старом работ над эндпоинтом команда QA-пишет тест на структуры запроса и ответа в Postman;</li><li>В мёрж реквест разработчик прикладывает два скриншота - как тест проходит с новым и старым бэком.</li></ol></div><p>Но незадолго до введения этого правила я уволил стажёра (спойлер 😱), которая генерировала большинство багов обратной совместимости, поэтому сложно сказать, что внесло больший вклад - скрины в МРах или увольнение стажёра.</p><p>А ошибки в сценариях использования (как негативных, так и позитивных) мы сейчас постепенно изводим возвратом к принципам тестирования ЭП.</p></section><section class="doc-section level-4"><h5 id=_хрупкость_тестов><a class=link href=#_хрупкость_тестов>Хрупкость тестов</a></h5><p>Так же мы поплатились за сетап БД SQL-скриптами.
Во-первых, изначально для моков старого бэка ответы генерировались из чёрт знает каких данных (текущего состояния БД на рабочей машине разработчика).
Соответственно, когда мы эти методы переносили в новый бэк, то для написания скриптов сетапа фикстуры приходилось героически определять входные данные, которые должны быть поданы в операцию чтобы получить заданный результат.</p><p>Второй проблемой, актуальной до сих пор, стала хрупкость тестов.
Во время реинжиниринга она проявлялась в том, что при переносе на новый бэк внутреннего эндпоинта приходилось прописывать скрипты сетапа БД для него во все тесты, в рамках которых этот эндпоинт вызывался.
А сейчас - при изменении схемы БД приходится править сетап фикстуры для множества тестов.</p><p>Первую проблему мы частично решили введением "эталонной БД" - взяли дамп с одного из стендов и для генерации мок-данных запускали бэк на нём.</p><p>А с хрупкостью тестов живём до сих пор и переводим их на публичное АПИ по мере появления проблем.</p></section></section></section><section class="doc-section level-2"><h3 id=_тестирование_силами_команды_qa><a class=link href=#_тестирование_силами_команды_qa>Тестирование силами команды QA</a></h3><p>План тестирования командой QA сводился к паре фраз: "Тестировать будем на дев стенде и стейдже. На деве - через Постаман, на стейдже - через МП".</p><p>Но и в этом плане мы тоже быстро уткнулись в дыру - как тестировать эндпоинт?</p><p>На момент начала реинжиниринга бэк-команда видела проект в первый раз, а команды QA и мобильной разработки работали с ним четыре месяца.
Поэтому ответить на вопрос "где этот эндпоинт используется?" сходу не мог никто и определение сценариев, которые он мог затронуть, и тест кейсов, которыми его можно проверить превращалось в целое расследование.</p><p>Эту проблему мы в полной мере так и не решили до самого конца проекта реинжиниринга - буду благодарен, если расскажете в комментариях хороший способ её решения.</p></section><section class="doc-section level-2"><h3 id=_модель_ветвления><a class=link href=#_модель_ветвления>Модель ветвления</a></h3><p>Модель ветвления я не планировал - она сама собой как-то оказалась <a href=https://docs.gitlab.cn/14.0/ee/topics/gitlab_flow.html>GitLab Flow</a>-ом.</p><p>Изначально у нас было три постоянных ветки:</p><div class="olist arabic"><ol class=arabic><li>re-integration (от reengeineering) - деплоится на дев стенд;</li><li>develop - деплоится на стейдж;</li><li>master - деплоится на прод;</li></ol></div><p>Далее, общий процесс <s>был</s> теоретически должен был быть такой:</p><div class="olist arabic"><ol class=arabic><li>Разработчики создают фича ветки от re-integration;</li><li>Делают фичи и проходят ревью;</li><li>Мёржат фича ветки в re-integration;</li><li>Команда QA проверяет фичи через Postman на деве;</li><li>Раз в спринт, re-integration мёржится в develop;</li><li>Команда QA проверяет работу МП;</li><li>После аппрува - develop мёржится в master.</li></ol></div><p>Баги чинятся в ветках отрезанных от постоянной ветки соответствующей стенду, на котором баг найден.
После фикса фича ветки мёржатся в постоянную, и бэкпортятся на более "ранние" ветки, при необходимости.</p><p>И из-за изрядной доли хаоса в процессах разработки и тестирования, особенно на ранних этапах у нас были две проблемы:</p><div class="olist arabic"><ol class=arabic><li>Довольно много багов находили уже на стейдже или проде;</li><li>Существенную часть хотфиксов этих багов забывали бэкпортить в более "ранние" ветки.</li></ol></div><p>Плюс куча церемоний и задержек - каждый мёрж проходил через пайплайн сборки и тестирования, который занимал 5-10 минут.</p><p>Пострадав с этими проблемами я начал думать над альтернативами.</p><p><a href=https://nvie.com/posts/a-successful-git-branching-model/>Git Flow</a> отмёл сразу, потому как там ещё больше церемоний, которые в нашем случае (единственная релизная версия) не нужны.</p><p><a href=https://docs.github.com/en/get-started/quickstart/github-flow>GitHub Flow</a> меня отпугнул тем, что "по феншую" предполагает Continuous Deployment, а мы к этому до сих пор не готовы.</p><p>Погуглив ещё я нашёл <a href=https://www.endoflineblog.com/oneflow-a-git-branching-model-and-workflow>OneFlow</a>.
Он мне показался разумным компромиссом между GitLab Flow и GitHub Flow и один спринт мы благополучно провели по нему.</p><p>А потом я решил, что "право имею" и придумал свой флоу - GitHub Flow с кодфризами и ручным деплоем.</p><p>Общая схема работы по нему следующая:</p><div class="olist arabic"><ol class=arabic><li>Есть одна постоянная ветка - master;</li><li>Разработчики создают фича ветки от мастера и мёржат их туда же;</li><li>Мастер автоматически деплоится на дев-стенд;</li><li>На 7-ой день спринта я вешаю на мастер тэг vX-rc, объявляю код фриз и запрещаю разработчикам мёржи в мастер;</li><li>QA гоняют тесты на деве;</li><li>На 10-ый день спринта и после аппрува QA я вешаю на мастер тэг vX-release и деплою его на стейдж;</li><li>На 11-ый день спринта, я смотрю как на стейдже прошли автотесты и что при этом в логах и если всё ок - деплою тег в прод.</li></ol></div><p>Для хотфикса схема работы такая:</p><div class="olist arabic"><ol class=arabic><li>Разработчик создаёт фича-ветку от тэга на проде;</li><li>По готовности - деплоим эту ветку на стейдж;</li><li>QA проверяют фикс и после аппрува я вешаю на ветку тэг vX.y-release и деплою его в прод;</li><li>Фича ветка ребейзится на мастер и мёржится.</li></ol></div><p>Тут ещё стоит сказать, что модель слияния у нас отчаянная - мы ведём линейную историю.
То есть мёржы делаем через "fast forward" (ребейзим фича ветки на мастер перед мёржем), да ещё и со сквошем по умолчанию.
Допускаю, что в один ужасный момент я пожалею об этой схеме, но последние полгода полёт нормальный и работать с историей стало существенно приятнее.</p></section><section class="doc-section level-2"><h3 id=_выгрузки><a class=link href=#_выгрузки>Выгрузки</a></h3><p>Я сильно ошибся в оценке реализации пары фич.
Это две схожие фичи в админке, которые позволяют просматривать списки пациентов и событий дневников.
Казалось бы - что там делать?</p><p>Проблема с ними в том, что данные лежат в разных БД и их планируется много (уже сейчас 300к строк, прирост по 3к/сутки и скорость прироста увеличивается).
При этом надо обеспечить стандартные фичи - пагинацию, сортировку по любому полю и фильтрацию по любому набору полей.
Плюс по требованиям необходимо обеспечивать выгрузку в xlsx с лимитом на количество строк равным лимиту самого формата - чуть больше одного миллиона.
В итоге мы руками сделали <a href=https://en.wikipedia.org/wiki/Block_nested_loop>block nested loop join</a>, о чём я чуть подробнее написал в <a href=https://azhidkov.pro/microposts/23/06/streaming-join/>отдельном микропосте</a>.</p><p>В результате вместо запланированных 104 часов на эту работу ушло 175.75 часов.</p></section><section class="doc-section level-2"><h3 id=_баги_net_бэка><a class=link href=#_баги_net_бэка>Баги .net-бэка</a></h3><p>При планировании я совсем не учитывал поддержку изначальной версии системы.
И хотя разработка была заморожена и новых фич не было - несколько раз в kotlin-команду прилетали старые баги оригинальной системы, которые проявились только после появления реальных пользователей.
Но нам повезло, багов было не много и они были простые и их исправление съело не много времени.</p></section><section class="doc-section level-2"><h3 id=_стажёр><a class=link href=#_стажёр>Стажёр</a></h3><p>По среди реинжиниринга мне пришлось уволить стажёра.
Вообще, положа руку на сердце, её надо было уволить намного раньше, но я всё давал шансы.
Пока она не пропала на несколько дней.
И даже тогда я дал ещё один шанс, но, появившись на день, она тут же снова пропала и тут моё терпение лопнуло.</p><p>Удивительно (на самом деле нет) - но на скорость работы команды это никак не повлияло.
Видимо та польза, которую она приносила, полностью компенсировалась проблемами которые, которые она порождала в процессе работы - мучительно долгие ревью, больше количество ошибок, иногда код который проходил только тесты, написанные для подтверждения его работоспособности, а не подтверждения его соответствия требованиям.</p><aside class=sidebar><h6 class=block-title>Что я вынес для себя</h6><div class="olist arabic"><ol class=arabic><li>При старте нового проекта вообще и особенно при старте проекта реинжинринга с новой командой, первые один-два спринта будут блинами комом и надо быть готовым (заложить в план) к тому, что их цели не будут выполнены даже на 50%;</li><li>Надо придерживаться принципов тестирования Эргономичного подхода - писать тесты на сценарии использования, писать тесты через публичное API, покрывать тестами негативные кейсы;</li><li>Перед началом реинжиниринга надо построить карту, по которой можно быстро определять тест кейсы, которые позволят протестировать каждый эндпоинт;</li><li>GitHub Flow с кодфризами вполне подходит для проектов с одной релизной версией, не готовых к CD.
В следующий раз можно так же использовать его;</li><li>Классики правы - задачи, которые на глаз оцениваются в три и более дня работы, надо всё-таки детально проектировать и декомпозировать до подзадач размером до одного дня;</li><li>Даже если заморозить разработку оригинальной системы, она всё равно может потребовать ресурсов на поддержку;</li><li>Перед стартом проекта надо подумать о своей команде - всем ли я доверяю, все ли дойдут до конца, планируются ли у кого-то отпуск?
Выявленные риски стоит заложить в план, в виде люфта на решение проблем и заранее продумать план, что делать если они выстрелят.</li></ol></div></aside></section></section><section class="doc-section level-1"><h2 id=_факапы_в_проде><a class=link href=#_факапы_в_проде>Факапы в проде</a></h2><p>Для начала надо прояснить что я имею ввиду под факапом и продом.</p><p>Под факапом я понимаю проблему конечных пользователей, с которой к нам пришёл заказчик.</p><p>Касательно прода - это окружение, которым пользуется заказчик и реальные пользователи, и у нас это не так страшно, как вы могли подумать.
Первые два наиболее багоёмких месяца работы (ноябрь и декабрь 2022 года) реальных пользователей у нас не было - приложением кроме команды разработки пользовались буквально несколько человек со стороны заказчика и близких к нему врачей.</p><p>Реальные пользователи, в количестве ста человек, к нам пришли в начале января 2023 года.
И далее был линейный рост примерно по сто человек в месяц.
Соответственно, на момент окончания реинжирининга в апреле 2023 года у нас было порядка 400 человек реальных пользователей.</p><p>И под такое определение за весь реинжиниринг у нас подошли три ошибки.</p><section class="doc-section level-2"><h3 id=_приглашение_в_наблюдатели><a class=link href=#_приглашение_в_наблюдатели>Приглашение в наблюдатели</a></h3><p>Первый факап в проде случился после первого же релиза нового бэка.</p><p>У нас есть функциональность приглашения пользователя в наблюдатели по емейлу.
В оригинальном бэке она работала так:</p><div class="olist arabic"><ol class=arabic><li>Сервис share идёт в сервис accounts и смотрит зарегистрирован ли пользователь с таким емейлом;</li><li>Сервис share отадёт команду сервису email-notifications на отправку емейла и включает в неё флаг accountExists</li><li>Сервис email-notifications формирует ссылку, включающую этот флаг и отправляет письмо на указанный емейл;</li><li>Пользователь проходит по ссылке;</li><li>Фронт смотрит на флаг и либо редиректит пользователя на форму ввода пароля, либо на главную/форму аутентификации.</li></ol></div><p>И при реинжиниринге сервиса email-notifications, разработчик потерял "s" в имени поля флага в классе входящего DTO команды.
В результате ссылка всегда отправлялась с флагом равным <code>false</code> и приглашение в наблюдатели существующего пользователя ломалось.</p><p>Проблема дополнительно усугубилось тем, что в это же время и в этой же функциональности нашли и починили баг (или несколько - сейчас уже не могу раскопать) на фронте, и мы несколько дней разводили кто и где ошибся.</p></section><section class="doc-section level-2"><h3 id=_поиск_наблюдаемого><a class=link href=#_поиск_наблюдаемого>Поиск наблюдаемого</a></h3><p>Второй факап у нас случился уже ближе к концу реинжиниринга.</p><p>У врача есть возможность искать своих пациентов.
В старом бэке поиск выполнялся и по имени и по логину.
А при реинжиниринге в SQL-запросе поиска потеряли сравнение с именем пациента.</p><p>Соответственно у врачей внезапно перестал работать привчный для них способ поиска.</p></section><section class="doc-section level-2"><h3 id=_обработка_протухших_токенов><a class=link href=#_обработка_протухших_токенов>Обработка протухших токенов</a></h3><p>Последний релиз реинжиниринга у нас тоже отметился факапом.</p><p>МП у нас "реактивно" обновляют токены - выполняяют обновление по 401-ой ошибке, а не до истечения срока его действия.
А при реализации обновления токена разработчик пропустил, что библиотека работы с JWT выбрасывает исключение и в случае валидного, но протухшего токена.</p><p>И когда мы зарелизали функциональность обновления токенов на 400 реальных пользователей, их начало выбрасывать из приложения каждые 15 минут.
А мы начали икать каждые 15 минут.</p></section><section class="doc-section level-2"><h3 id=_бонус_аутентификация_по_куке><a class=link href=#_бонус_аутентификация_по_куке>Бонус: аутентификация по куке</a></h3><p>Это не совсем факап в проде по моему определению, так как его нашли наши QA.
Однако и критичность, и "фейспалмность" его зашкаливают, поэтому я решил его включить в список.</p><p>У нас запросы к бэку аутентифицируются по JWT-токену.
Но при настройке Spring Security я забыл отключить аутентификацию по куке.
Соответствено, логаут на вэбе выглядел работающим, но не имел никакого эффекта.
И когда следующий пользователь логинился со своими учётными данными - он получал доступ к аккаунту предыдущего пользователя.</p><p>Благо это было на самом начальном этапе реинжиниринга, когда у нас ни настоящих пользователей, ни настоящих данных ещё не было.</p><hr><p>Примечательно, что первых трёх факапов можно было бы избежать, если бы мы придерживались принципов тестирования ЭП.</p><p>Факап с приглашением бы отловили когда поняли, что тесты двух юз кейсов должны отличаться флагом в ссылке в письме, добавили бы забытую проверку и обнаружили, что один из них не проходит.</p><p>Факап с поиском очевидным образом бы отловил тест юз кейса поиска по имени.</p><p>Факап с протухшими токенами бы отловил негативный тест юз кейса обновления протухшего токена.</p><aside class=sidebar><h6 class=block-title>Что я вынес для себя</h6><div class="olist arabic"><ol class=arabic><li>И снова - надо придерживаться принципов тестирования Эргономичного подхода.</li></ol></div></aside></section></section><section class="doc-section level-1"><h2 id=_результаты><a class=link href=#_результаты>Результаты</a></h2><p>Итого, проект реинжиниринга длился ~5.5 месяцев с 31 октября 2022 года по 14 апреля 2023 года (дата релиза в прод фикса обновления токена).
По Jira общие фактические трудозатраты на разработку, поддержку и коммуникации составили 1402.75 часа (175 человеко/дней).</p><aside class="admonition-block note" role=note><h6 class="block-title label-only"><span class=title-label>Note:</span></h6><p>Точность попадания в подробную оценку оказалась феноменальной - 175 человеко-дней по Jira против 177 дней на странице Confluence, датированной 22 ноября 2022 года.
Как так получилось - я не знаю.
Думаю - немного опыта, немного интуиции, немного закона больших чисел и немного везения.</p></aside><p>В результате у нас получилось:</p><div class="olist arabic"><ol class=arabic><li>23,944 строк кода;</li><li>730 классов;</li><li>234 теста (преимущественно интеграционных);</li><li>100% покрытие эндпоинтов тестами;</li><li>93.2% покрытия строк кода тестами;</li><li>1:30 минут полное время сборки, включая все тесты кода, тесты архитектуры, detekt, сборку и верификацию покрытия кода;</li><li>84 баг, который нашли мы или QA;</li><li>3 бага, которые нашли пользователи или заказчик.</li></ol></div><p>Стоило ли оно того?
Безусловно да.</p><p>Через три месяца после завершения реинжиниринга я проанализировал задачи в Jira и написал об этом <a href=https://azhidkov.pro/microposts/23/07/project-e-retro-v2/>подробный пост</a>.
Главный вывод этого поста: после завершения реинжиниринга мы стали работать в два раза быстрее, в том числе за счёт того, что стали допускать в два раза меньше ошибок.</p></section><section class="doc-section level-1"><h2 id=_выводы_из_всей_истории><a class=link href=#_выводы_из_всей_истории>Выводы из всей истории</a></h2><p>Что я буду делать по другому в своём следующем проекте реинжиниринга:</p><div class="olist arabic"><ol class=arabic><li>Сразу отслеживать прогресс в процентах;</li><li>Закладывать больше времени на набор крейсерской скорости работы командой в первые два спринта;</li><li>Следовать принципам тестирования Эргономичного подхода;</li><li>Построю "карту тестирования" - какими юзкейсами/тест кейсами тестировать каждый эндпоинт;</li><li>Декомпозирую задачи до размера в один (максимум три) дня;</li><li>Заложу время на саппорт оригинальной версии системы;</li><li>Внимательнее отнесусь к команде - кому можно доверять, кто с высокой вероятностью уволится, у кого какие планы на отпуск, и какой у меня есть кадровый резерв на случай выпадения человека.</li></ol></div><p>Что я буду делать так же в следующий раз:</p><div class="olist arabic"><ol class=arabic><li>Работать по принципам Эргономичного подхода;</li><li>Использовать те же принципы аргументации и структуру презентации при обосновании необходимости реинжиниринга;</li><li>Планировать работы на базе графа зависимостей системы;</li><li>Работать по спринтам;</li><li>Вести дейлики по задачам, а не людям;</li><li>Релизаться в прод как можно раньше и в целом следовать стратегии Strangler Fig.</li></ol></div><p>На этом заканчивается организационно-менеджерская часть ретроспективы, и в следующем посте я расскажу как у нас устроен проект внутри.</p></section></article></section></div></main><script src=/js/app.js></script></body></html>